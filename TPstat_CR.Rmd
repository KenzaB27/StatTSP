---
title: "TP Statistique"
author: "BOUZID Kenza, JEANNE Nathan, CANNEDDU Hugo"
date: "1 avril 2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
set.seed(287)
knitr::opts_chunk$set(echo = TRUE)

## il est possible qu'avant d'installer le package TSPpackage vous deviez installer ou ré-installer Rcpp
#install.packages('Rcpp')

# install.packages('./TSPpackage_1.0.tar.gz',repos=NULL,type='bin') ## pour linux
# install.packages('./TSPpackage_1.0.zip',repos=NULL,type='bin')    ## pour windows
## je ne peux pas fournir de package pour mac...

## Appels aux packages, après les avoir installés !
library(sp)
library(maps)
library(microbenchmark)
library(TSP)
library(TSPpackage)
```
Voici le plan de ce qui sera fait dans le TP.

# 0. Visualisation de chemins

Lecture du fichier des villes :

```{r, echo=TRUE}
villes <- read.csv('DonneesGPSvilles.csv',header=TRUE,dec='.',sep=';',quote="\"")
str(villes)
```
Représentation des chemins par plus proches voisins et du chemin optimal :
```{r, echo=TRUE}
coord <- cbind(villes$longitude,villes$latitude)
dist <- distanceGPS(coord)
voisins <- TSPnearest(dist)

pathOpt <- c(1,8,9,4,21,13,7,10,3,17,16,20,6,19,15,18,11,5,22,14,12,2)

par(mfrow=c(1,2),mar=c(1,1,2,1))
plotTrace(coord[voisins$chemin,], title='Plus proches voisins')
plotTrace(coord[pathOpt,], title='Chemin optimal')
```


Les longueurs des trajets (à vol d'oiseau) valent respectivement, pour la méthode des plus proches voisins :
```{r, echo=FALSE}
voisins$longueur
```
et pour la méthode optimale :
```{r, echo=FALSE}
calculeLongueur(dist,pathOpt)
```

Ceci illustre bien l'intérêt d'un algorithme de voyageur de commerce. Nous allons dans la suite étudier les performances de cet algorithme.


# 1. Comparaison d'algorithmes

Nombre de sommets fixes et graphes "identiques".

```{r, echo=TRUE}
      n <- 10
sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
```

## 1.1. Longueur des chemins

Comparaison des longueurs de différentes méthodes : 

### boxplots
   
```{r, echo=FALSE}
  X1 <- vector(mode="integer", length=50)
  X2 <- vector(mode="integer", length=50)
  X3 <- vector(mode="integer", length=50)
  X4 <- vector(mode="integer", length=50)
  X5 <- vector(mode="integer", length=50)
  n <-10
  for(i in 1:50)
  {
    sommets <- data.frame(x = runif(n), y = runif(n))
    couts <- distance(sommets)
    v1<-TSPbranch(couts)
    v2<-TSPnearest(couts)
    v3<-TSPsolve(couts, "repetitive_nn")
    v4<-TSPsolve(couts, "farthest_insertion")
    v5<-TSPsolve(couts, "two_opt")
    X1[i]<-v1
    X2[i]<-v2$longueur
    X3[i]<-v3
    X4[i]<-v4
    X5[i]<-v5
  }

  
  mat <- cbind(X1,X2,X3,X4,X5)
  par(mfrow=c(1,1))
  boxplot(mat,notch=TRUE)
```   

Les boxplots ci dessus correspondent respectivement aux algorithme "branch", "nearest", "repetitive_nn", "farthest_insertion" et "two_opt". (de gauche à droite).

la boite de l'algorithme Branch & Bound nous permet de voir qu'après 50 essais, cet algorithme obtient la plus petote valeur minimale, maximale et moyenne, ce qui en fait l'algorithme avec les meilleurs résultats sur les 50 tests parmi les 5 méthodes de calcul des plus courts chemins disponibles.

On observe sur le diagramme a moustache un léger avantage pour l'algorithme Branch & Bound qui obtient une longueur des chemin hamiltonien moyenne plus courte sur les 50 exécutions.

### test entre 'nearest' et 'branch'

  Nous allons maintenant comparer les algorithmes "nearest" et Branch & Bound. Pour cela, nous allons réaliser un test d'hypothèses paramétriques.

      Soit m<sub>nn</sub> et m<sub>b</sub> les espérances respectives des algorithmes des plus proches voisins et de Branch&Bound. Les hypothèses de notre test vont être :

  * (H<sub>0</sub>) -> m<sub>nn</sub> - m<sub>b</sub> <= 0
  * (H<sub>1</sub>) -> m<sub>nn</sub> - m<sub>b</sub> > 0   
   
Nous cherchons ainsi la p_value afin de rejetter ou non l'hypothèse.
On utilise le code ci-dessous avec X2 les résultats obtenus pour l'algorithme "nearest" et X1 pour Branch & Bound.
Le test porte ici sur l'espérance d'une loi normale (étant donné que les longueurs obtenues suivent une loi normale).

```{r, echo=TRUE}
  t.test(X2, X1, mu=0, paired=TRUE, alternative='greater')
```
On obtient une p_value de l'ordre de 10<sup>-11</sup>. 
Celle-ci est inférieure a alpha = 1%, on rejette donc l'hypothèse (H<sub>0</sub>) -> m<sub>nn</sub> - m<sub>b</sub> <= 0.
On a donc m<sub>nn</sub> > m<sub>b</sub> (H<sub>1</sub>), ou que l'espérance des longueurs obtenues avec Branch & Bound est plus faible que celles obtenues avec "de l'algorithme des plus proches voisins"nearest".

Au vu de données et de nos résultats on peut donc affirmer que l'algorithme Branch & Bound renvoie de meilleurs résultats que l'algorithme "nearest".


### tests 2 à 2 
   
   Nous allons maintenant comparer 2 à 2 les 5 algorithmes à notre dispositions et les longueurs du plus court chemin obtenues au terme des 50 exécutions. On applique ici la procédure de Bonferroni qui consiste à tester les hypothèses suivantes (avec i != j) :
   
  * (H<sub>0</sub>) -> m<sub>i</sub> = m<sub>j</sub>
  * (H<sub>1</sub>) -> m<sub>i</sub> != m<sub>j</sub> 

Avec  m<sub>i</sub> et m<sub>j</sub> la moyenne des longueurs obtenues par 2 algorithmes au choix.
        
Le test nous donne le résultat ci-dessous :
   
```{r, echo=FALSE}
results<- c(X1,X2,X3,X4,X5)
methods<- c(rep("branch", 50),rep("nearest", 50),rep("repetitive_nn", 50),rep("farthest_insertion", 50),rep("two_opt", 50))

pairwise.t.test(results,methods,adjust.method="bonferroni")
```

  On obtient un tableau des différentes p_valeurs obtenues entre les algorithmes 2 à 2.
Pour chaque p-value <= alpha (où alpha représente le risque, par défaut 5%), on rejette H<sub>0</sub>. 
Ainsi pour chaque rejet les algorithmes donnent des longueurs moyennes différentes (H<sub>1</sub>), en revanche ne pas rejeter l'hypothése ne permet pas d'affirmer que les algorithmes ont la même longeur moyenne mais il est possible que leurs résultats soient proches.

Dans nos résultats, les algorithmes dont l'esperance des longueurs obtenues n'est pas identiques (avec un risque alpha = 5%) sont les couples ci-dessous :

  * nearest / branch
  * farthest_insertion / nearest
  * two_opt / branch
  * repetitive_nn / nearest
  * two_opt / repetitive_nn

  On remarque que les algorithmes "nearest" et Branch & Bound ont des espérances des longueurs obtenues différentes, ce qui rejoint les résultats obtenus précédemment.
  

## 1.2. Temps de calcul

Finalement nous allons effectuer une comparaison des temps d'exécution à l'aide du package microbenchmark afin de déterminer l'algorithme le plus performant.

Exemple d'application de microbenchmark :
```{r, echo=TRUE}
m<-microbenchmark(TSPbranch(couts),TSPnearest(couts), TSPsolve(couts, "repetitive_nn"), TSPsolve(couts, "farthest_insertion"), TSPsolve(couts, "two_opt"), times=20, setup={ n<-10
  sommets <- data.frame(x = runif(n), y = runif(n))
  couts <- distance(sommets)
})

summary(m)
```

Avc les résultats obtenues on peut observer que les algorithmes "two_opt" et "nearest" sont les plus rapides et ont donc des temps d'exécution proches (même ordre de grandeur de quelques centaines de secondes). 
On remarque également que l'algorithme Branch & Bound obtient la note **b**, note moyenne ("repetitive_nn" ayant la pire note avec un temps d'exécution moyen 2 fois plus long que le Branch & Bound et 50 fois plus long que "nearest", le plus rapide). 

Branch & Bound est donc moins performand (en temps) que tous les autres algorithmes, cependant, il reste celui proposant les meilleurs résultats. 


# 2. Etude e la complexité de l'algorithme Branch and Bound

## 2.1. Comportement par rapport au nombre de sommets : premier modèle

Récupération du temps sur 10 graphes pour différentes valeurs de $n$.

Ajustement du modèle linéaire de $\log(temps)^2$ en fonction de $n$.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

## 2.2. Comportement par rapport au nombre de sommets : étude du comportement moyen

Récupération du temps moyen.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de $n$.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.
  

## 2.3. Comportement par rapport à la structure du graphe

Lecture du fichier 'DonneesTSP.csv'.

Ajustement du modèle linéaire de $\log(temps.moy)^2$ en fonction de toutes les variables présentes. Modèle sans constante.

Mise en \oe uvre d'une sélection de variables pour ne garder que les variables pertinentes.

Analyse de la validité du modèle : 

  * pertinence des coefficients et du modèle, 
  
  * étude des hypothèses sur les résidus.

